{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C2. Intro to Keras",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrkfeller/YCBS_notes/blob/master/C2_Intro_to_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xhW0sbXbdnC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pyyaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0B3_fj18q-Sz",
        "colab_type": "code",
        "outputId": "bac48400-9d48-4ba9-8596-1e60c6e8b296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!apt install graphviz\n",
        "!pip install pydot pydot-ng\n",
        "!echo \"Double check with Python 3\"\n",
        "!python -c \"import pydot\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pydot-ng in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.1)\n",
            "Double check with Python 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7zwaBdZJhdPZ",
        "colab_type": "code",
        "outputId": "6c899a09-e45c-4412-8fe1-9517bd2988db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.0-rc2\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oPCGxnvKKMgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Models types\n",
        "### Sequential\n",
        "Simple stack of layers\n",
        "### Functional\n",
        "Multi input, multi output, shared layers, non sequential flows\n",
        "### Model Subclassing\n",
        "Customizable, define foward pass with ```call``` method. Enables [eager execution](https://www.tensorflow.org/guide/eager#build_a_model)"
      ]
    },
    {
      "metadata": {
        "id": "T3gDzVSZM3DX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "features = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W65lRhammQkO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sequential Model"
      ]
    },
    {
      "metadata": {
        "id": "2jJXz3MkhlsB",
        "colab_type": "code",
        "outputId": "e1410d93-8fe2-492a-f036-81007775c08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "cell_type": "code",
      "source": [
        "# maximum simplicity\n",
        "seq_model = Sequential()\n",
        "seq_model.add(Dense(20, activation='relu', input_shape=(32,)))\n",
        "seq_model.add(Dense(20, activation='relu'))\n",
        "seq_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "seq_model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "seq_model.fit(features, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 1s 717us/sample - loss: 11.5995 - acc: 0.1020\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 84us/sample - loss: 11.5523 - acc: 0.1090\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 83us/sample - loss: 11.5450 - acc: 0.1070\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 84us/sample - loss: 11.5413 - acc: 0.1000\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 78us/sample - loss: 11.5387 - acc: 0.1150\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 86us/sample - loss: 11.5372 - acc: 0.1190\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 82us/sample - loss: 11.5353 - acc: 0.1160\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 78us/sample - loss: 11.5346 - acc: 0.1180\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 87us/sample - loss: 11.5340 - acc: 0.1100\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 78us/sample - loss: 11.5327 - acc: 0.1170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb24b1cb4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "KQhkaZ28mTA9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Functional Model\n",
        "[example](https://cdn-images-1.medium.com/max/2600/1*6hF97Upuqg_LdsqWY6n_wg.png)"
      ]
    },
    {
      "metadata": {
        "id": "VBHDpI2kKY7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# more full featured and flexible\n",
        "inputs = keras.Input(shape=(32,))\n",
        "x = Dense(20, activation='relu')(inputs)\n",
        "y = Dense(20, activation='relu')(x)\n",
        "outputs = Dense(10, activation='softmax')(y)\n",
        "\n",
        "func_model = keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "func_model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "func_model.fit(features, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRa8kh2-mVGf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Subclassing"
      ]
    },
    {
      "metadata": {
        "id": "PA-jfeUzLdKO",
        "colab_type": "code",
        "outputId": "8a229b17-0684-42bf-c0a5-e678025b9f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "cell_type": "code",
      "source": [
        "# maximally flexible and hackable\n",
        "class ScModel(keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(ScModel, self).__init__()\n",
        "    self.dense1 = Dense(20, activation='relu')\n",
        "    self.dense2 = Dense(20, activation='relu')\n",
        "    self.dense3 = Dense(10, activation='softmax')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    return self.dense3(x)\n",
        "  \n",
        "sc_model = ScModel()\n",
        "\n",
        "sc_model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "sc_model.fit(features, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 1s 703us/sample - loss: 11.6123 - acc: 0.1040\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 75us/sample - loss: 11.5532 - acc: 0.1030\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 75us/sample - loss: 11.5443 - acc: 0.1070\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 85us/sample - loss: 11.5396 - acc: 0.1050\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 77us/sample - loss: 11.5373 - acc: 0.1070\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 83us/sample - loss: 11.5355 - acc: 0.1210\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 84us/sample - loss: 11.5340 - acc: 0.1190\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 85us/sample - loss: 11.5330 - acc: 0.1250\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 84us/sample - loss: 11.5320 - acc: 0.1250\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 80us/sample - loss: 11.5308 - acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb24acc7b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "j3ItCImGoDSg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize model\n",
        "\n",
        "The summary is useful for simple models, but can be confusing for models that have multiple inputs or outputs.\n",
        "\n",
        "Keras also provides a function to create a plot of the network neural network graph that can make more complex models easier to understand.\n",
        "\n",
        "The plot_model() function in Keras will create a plot of your network. This function takes a few useful arguments:\n",
        "\n",
        "* ```model```: (required) The model that you wish to plot.\n",
        "* ```to_file```: (required) The name of the file to which to save the plot.\n",
        "* ```show_shapes```: (optional, defaults to False) Whether or not to show the output shapes of each layer.\n",
        "* ```show_layer_names```: (optional, defaults to True) Whether or not to show the name for each layer."
      ]
    },
    {
      "metadata": {
        "id": "7KmC42hroBol",
        "colab_type": "code",
        "outputId": "20f0e329-f558-4aec-a3f8-9707a2874c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "cell_type": "code",
      "source": [
        "seq_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_35 (Dense)             (None, 20)                660       \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 1,290\n",
            "Trainable params: 1,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7cDLp2yp3kY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[fully connected NN](https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0402.png)"
      ]
    },
    {
      "metadata": {
        "id": "Wrzmlp4npIXK",
        "colab_type": "code",
        "outputId": "3c9ddfe8-7a96-43fe-bd02-ae7802d3ccab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "mod = func_model\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    mod, \n",
        "    to_file='{}.png'.format(mod), \n",
        "    show_shapes=True, \n",
        "    show_layer_names=True\n",
        ")\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='{}.png'.format(mod))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAGVCAIAAABhGZ0jAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nWkDOBYFA0ML/ADQGgLW+9e6JAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 186,
              "height": 202
            }
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "90NHWXygtgu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
        "data and a `tf.data.Dataset`.\n",
        "\n",
        "To *evaluate* the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "metadata": {
        "id": "fW5GZmB_jI_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unseen data\n",
        "new_features  = np.random.random((1000, 32))\n",
        "new_labels = np.random.random((1000, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnbrMxQMjjN2",
        "colab_type": "code",
        "outputId": "13980491-50b3-4bb1-ee33-2557c512f6f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "predicted_labels = sc_model.predict(new_features)\n",
        "predicted_labels[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10614535, 0.09762572, 0.10136784, 0.09797994, 0.10243566,\n",
              "       0.10118973, 0.10109984, 0.09669265, 0.09721795, 0.09824526],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "H6tOtNLwjpje",
        "colab_type": "code",
        "outputId": "bae4f849-d959-40d3-946c-731b34a11b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "sc_model.evaluate(new_features, new_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 1s 640us/sample - loss: 11.5792 - acc: 0.0990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.579156860351562, 0.099]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "P3RAov0piqQr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input tf.data datasets\n",
        "\n",
        "Use the Dataset API to scale to large datasets\n",
        "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
        "method:\n",
        "\n",
        "Here, the `fit` method uses the `steps_per_epoch` argument—this is the number of\n",
        "training steps the model runs before it moves to the next epoch. Since the\n",
        "`Dataset` yields batches of data, this snippet does not require a `batch_size`."
      ]
    },
    {
      "metadata": {
        "id": "j_f1u0KyL383",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K14bKV7SiXzo",
        "colab_type": "code",
        "outputId": "65d6af62-915b-4ca7-e90d-6082e55ec372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "cell_type": "code",
      "source": [
        "sc_model.fit(dataset, epochs=10, steps_per_epoch=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 2s 75ms/step - loss: 11.5324 - acc: 0.1271\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5485 - acc: 0.1325\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5241 - acc: 0.1314\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5251 - acc: 0.1325\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5369 - acc: 0.1346\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5476 - acc: 0.1325\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5098 - acc: 0.1400\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5105 - acc: 0.1325\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 11.5381 - acc: 0.1357\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5361 - acc: 0.1410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb24b911e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "jJSxjNQqk6B8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Custom layers\n",
        "\n",
        "[Arguments](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
        "-\n",
        "[Implementation](https://github.com/keras-team/keras/blob/master/keras/layers/core.py)\n",
        "\n",
        "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
        "the following methods:\n",
        "\n",
        "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
        "  method.\n",
        "* `call`: Define the forward pass.\n",
        "* `compute_output_shape`: Specify how to compute the output shape of the layer\n",
        "  given the input shape.\n",
        "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
        "  and the `from_config` class method.\n",
        "\n",
        "Here's an example of a custom layer that implements a `matmul` of an input with\n",
        "a kernel matrix:"
      ]
    },
    {
      "metadata": {
        "id": "vd_n_oj8ktYW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layers."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RpoNJ20KihgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
        "    # Create a trainable weight variable for this layer.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=shape,\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "    # Make sure to call the `build` method at the end\n",
        "    super(MyLayer, self).build(input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.output_dim\n",
        "    return tf.TensorShape(shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xemR242ak-yV",
        "colab_type": "code",
        "outputId": "c1fc88d4-a8c2-4dfe-c41e-bb96294930f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(MyLayer(10))\n",
        "model.add(layers.Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(features, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 1s 694us/sample - loss: 11.5555 - acc: 0.0810\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 96us/sample - loss: 11.5447 - acc: 0.0750\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 83us/sample - loss: 11.5418 - acc: 0.0870\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 80us/sample - loss: 11.5395 - acc: 0.1000\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 95us/sample - loss: 11.5371 - acc: 0.1150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb24c931048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "IwzvqjrLlJrZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Callbacks\n",
        "\n",
        "A callback is an object passed to a model to customize and extend its behavior\n",
        "during training. You can write your own custom callback, or use the built-in\n",
        "`tf.keras.callbacks` that include:\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
        "  regular intervals.\n",
        "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
        "  rate.\n",
        "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
        "  performance has stopped improving.\n",
        "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
        "  [TensorBoard](./summaries_and_tensorboard.md).\n",
        "\n",
        "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
      ]
    },
    {
      "metadata": {
        "id": "SkXcbKEflI7W",
        "colab_type": "code",
        "outputId": "cf117440-fa3d-4b0f-b65c-2b59e90b2130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "\n",
        "model.fit(features, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
        "          validation_data=(new_data, new_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 1s 712us/sample - loss: 11.5364 - acc: 0.1020 - val_loss: 11.5811 - val_acc: 0.1050\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 123us/sample - loss: 11.5339 - acc: 0.1150 - val_loss: 11.5801 - val_acc: 0.0950\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 121us/sample - loss: 11.5329 - acc: 0.1020 - val_loss: 11.5798 - val_acc: 0.1100\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 124us/sample - loss: 11.5305 - acc: 0.1290 - val_loss: 11.5814 - val_acc: 0.1030\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 125us/sample - loss: 11.5289 - acc: 0.1260 - val_loss: 11.5797 - val_acc: 0.1010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb251c43550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "31yq6mUxlZxN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Saving and Restoring\n",
        "### Weights only\n",
        "\n",
        "Save and load the weights of a model using `tf.keras.Model.save_weights`:\n",
        "\n",
        "### Configuration only\n",
        "\n",
        "A model's configuration can be saved—this serializes the model architecture\n",
        "without any weights. A saved configuration can recreate and initialize the same\n",
        "model, even without the code that defined the original model. Keras supports\n",
        "JSON and YAML serialization formats:\n",
        "\n",
        "### Entire model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the\n",
        "model's configuration, and even the optimizer's configuration. This allows you\n",
        "to checkpoint a model and resume training later—from the exact same\n",
        "state—without access to the original code."
      ]
    },
    {
      "metadata": {
        "id": "af1xTnLMlUwS",
        "colab_type": "code",
        "outputId": "d6bac5ad-735f-4182-e809-0eb29d26b01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(features, labels, batch_size=32, epochs=5)\n",
        "\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 1s 798us/sample - loss: 11.5484 - acc: 0.0990\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 97us/sample - loss: 11.5403 - acc: 0.0990\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 91us/sample - loss: 11.5380 - acc: 0.1100\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 101us/sample - loss: 11.5372 - acc: 0.1100\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 139us/sample - loss: 11.5367 - acc: 0.0990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EcomTxNE5K2h",
        "colab_type": "code",
        "outputId": "16317ac8-ffbd-49a2-f231-cd67fd841064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "results = model.predict(new_features)\n",
        "results[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10090098, 0.09588795, 0.10577583, 0.10140252, 0.10266129,\n",
              "       0.09999233, 0.09697979, 0.09318646, 0.1002841 , 0.10292869],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "GrpOFkPjhXYD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pretrained Models\n",
        "\n",
        "### Use pretrained model\n",
        "### Get embeddings from pretrained models\n",
        "### Finetune pretrained model"
      ]
    },
    {
      "metadata": {
        "id": "FjEmUrRGlE3U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtAYAEHXKBGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAoBgbX-Hoz0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[pretrained keras models](https://keras.io/applications/)\n",
        "\n",
        "[imagenet classes](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)"
      ]
    },
    {
      "metadata": {
        "id": "LaJ_AvtzjzyX",
        "colab_type": "code",
        "outputId": "e7212061-2207-4b80-fd28-12fab4fb4e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -O test.png https://www.freepngimg.com/thumb/corn/23-corn-png-image-thumb.png\n",
        "#!wget -O test.png https://vignette.wikia.nocookie.net/dino/images/f/f6/JW_triceratops.png/revision/latest?cb=20150407211112"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-21 00:17:58--  https://www.freepngimg.com/thumb/corn/23-corn-png-image-thumb.png\n",
            "Resolving www.freepngimg.com (www.freepngimg.com)... 88.99.162.33\n",
            "Connecting to www.freepngimg.com (www.freepngimg.com)|88.99.162.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38182 (37K) [image/png]\n",
            "Saving to: ‘test.png’\n",
            "\n",
            "test.png            100%[===================>]  37.29K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-02-21 00:17:58 (361 KB/s) - ‘test.png’ saved [38182/38182]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tvGO9WyqjmWG",
        "colab_type": "code",
        "outputId": "501b8f5b-da54-4c65-d41e-cb7ef7a293b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "img_path = 'test.png'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: [('n12144580', 'corn', 0.64657545), ('n13133613', 'ear', 0.3533439), ('n02226429', 'grasshopper', 2.1798884e-05)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QF5Gpp-rTzcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "31Vs2mDAJAEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1VnAZHlUeDE",
        "colab_type": "code",
        "outputId": "c5aac45c-c7c7-4a8d-f2a2-debe376c9f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Other way to do the same thing, just create another model\n",
        "emb_model = Model(inputs=model.inputs, outputs=model.get_layer('avg_pool').output)\n",
        "\n",
        "emb_model.predict(x).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "metadata": {
        "id": "OZmDklyGNuSq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning pre-trained model\n",
        "Provided that our dataset is not drastically different in context to the original dataset, we can use pretrained models like the one above to fine tune to a different task"
      ]
    },
    {
      "metadata": {
        "id": "cI6x46u9NtrV",
        "colab_type": "code",
        "outputId": "b4d56d6c-9679-49e0-8199-2c9888dd3502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "[print(l) for l in model.layers[-10:]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb246034fd0>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb245ff4be0>\n",
            "<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb246006780>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb246006ef0>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb245f35dd8>\n",
            "<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb245f354a8>\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7fb245f47390>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb245e5ebe0>\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fb245e5e8d0>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb245e75780>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "ERzr3uRMQRzb",
        "colab_type": "code",
        "outputId": "0d75eef0-4328-433c-8281-9cd0d1cf7369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "# remove the softmax layer\n",
        "model = Model(inputs=model.inputs, outputs=model.get_layer('avg_pool').output)\n",
        "[print(l) for l in model.layers[-10:]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb2460c2780>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb246034fd0>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb245ff4be0>\n",
            "<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb246006780>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb246006ef0>\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb245f35dd8>\n",
            "<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb245f354a8>\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7fb245f47390>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb245e5ebe0>\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fb245e5e8d0>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "metadata": {
        "id": "qvcxlZokKWMs",
        "colab_type": "code",
        "outputId": "2a4be0f5-9871-49c1-bb04-a05f66f03e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "# Freeze the previous layers\n",
        "for layer in model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# add a couple layers\n",
        "x = Flatten()(model.layers[-1].output)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(500, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "out = Dense(100, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=model.input, outputs=out)\n",
        "\n",
        "[print(l) for l in model.layers[-10:]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb245f354a8>\n",
            "<tensorflow.python.keras.layers.merge.Add object at 0x7fb245f47390>\n",
            "<tensorflow.python.keras.layers.core.Activation object at 0x7fb245e5ebe0>\n",
            "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7fb245e5e8d0>\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7fb24cd6b4e0>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb24cd6bb70>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fb24c934400>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb24c9346d8>\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fb24c935b00>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb24c935a90>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "metadata": {
        "id": "pZN-l2IzbhFw",
        "colab_type": "code",
        "outputId": "0d3f5cbd-9ffc-4eec-afff-4ae3f608111e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6848
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalizationV1) (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 56, 56, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 56, 56, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 56, 56, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 28, 28, 512)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 28, 28, 512)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 28, 28, 512)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 28, 28, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 14, 14, 1024) 0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 7, 7, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 1000)         2049000     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1000)         0           dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 500)          500500      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 500)          0           dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 100)          50100       dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,187,312\n",
            "Trainable params: 2,599,600\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fJIqzEuHUol1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCGw3jUNSlFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001, momentum=0.9), loss='caregorical_crossentropy')\n",
        "model.fit_generator(...,...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IsDT1y9mQ936",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Toy video-QA problem\n",
        "![sequence](https://storage.googleapis.com/nicksdemobucket/Screen%20Shot%202019-02-20%20at%202.17.39%20PM.png)\n",
        "![architecture](https://storage.googleapis.com/nicksdemobucket/Screen%20Shot%202019-02-20%20at%202.17.52%20PM.png)"
      ]
    },
    {
      "metadata": {
        "id": "SNDEpxR8Q-Oq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9VtSx3-XutP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_voc_size = # Size of vocabulary of possible answers\n",
        "data_generator = # input as question and "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JEzLGoJZXiRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "video = keras.Input(shape=(None, 150, 150, 3), name='video')\n",
        "cnn = InceptionV3(weights='imagenet',\n",
        "include_top=False,\n",
        "pooling='avg')\n",
        "cnn.trainable = False\n",
        "frame_features = layers.TimeDistributed(cnn)(video)\n",
        "video_vector = layers.LSTM(256)(frame_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FmqQ20GVRFaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question = keras.Input(shape=(None,), dtype='int32', name='question')\n",
        "embedded_words = layers.Embedding(input_voc_size, 256)(question)\n",
        "question_vector = layers.LSTM(128)(embedded_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vw4fNeaWRNDL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = layers.concatenate([video_vector, question_vector])\n",
        "x = layers.Dense(128, activation=tf.nn.relu)(x)\n",
        "predictions = layers.Dense(output_voc_size,\n",
        " activation='softmax',\n",
        " name='predictions')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4pStrrubRRCi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.Model([video, question], predictions)\n",
        "model.compile(optimizer=tf.AdamOptimizer(),loss=keras.losses.categorical_crossentropy)\n",
        "model.fit_generator(data_generator, steps_per_epoch=1000, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUrsPbBabv1x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Futher Reading\n",
        "* https://github.com/Dataweekends/zero_to_deep_learning_video \n",
        "* https://github.com/keras-team/keras/tree/master/examples \n",
        "* https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras \n",
        "* https://medium.com/tensorflow/tagged/keras\n",
        "* https://github.com/keras-team/keras"
      ]
    }
  ]
}