{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C7 Batch Normalization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrkfeller/YCBS_notes/blob/master/C7_Batch_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nTuetU4KaQ6G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ]
    },
    {
      "metadata": {
        "id": "QOBBtWfNaRWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VF8IcFOsaDcV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "y_cat = to_categorical(y, 10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat,\n",
        "                                                    test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OaHRFkI-aNY2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch Norm"
      ]
    },
    {
      "metadata": {
        "id": "WovvTHteaDkp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3m-v1j1Z3zd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def repeated_training(X_train,\n",
        "                      y_train,\n",
        "                      X_test,\n",
        "                      y_test,\n",
        "                      units=512,\n",
        "                      activation='sigmoid',\n",
        "                      optimizer='sgd',\n",
        "                      do_bn=False,\n",
        "                      epochs=10,\n",
        "                      repeats=3):\n",
        "    histories = []\n",
        "    \n",
        "    for repeat in range(repeats):\n",
        "        K.clear_session()\n",
        "\n",
        "        model = Sequential()\n",
        "        \n",
        "        # first fully connected layer\n",
        "        model.add(Dense(units,\n",
        "                        input_shape=X_train.shape[1:],\n",
        "                        kernel_initializer='normal',\n",
        "                        activation=activation))\n",
        "        if do_bn:\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        # second fully connected layer\n",
        "        model.add(Dense(units,\n",
        "                        kernel_initializer='normal',\n",
        "                        activation=activation))\n",
        "        if do_bn:\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        # third fully connected layer\n",
        "        model.add(Dense(units,\n",
        "                        kernel_initializer='normal',\n",
        "                        activation=activation))\n",
        "        if do_bn:\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        # output layer\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "        \n",
        "        model.compile(optimizer,\n",
        "                      'categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        h = model.fit(X_train, y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      epochs=epochs,\n",
        "                      verbose=0)\n",
        "        histories.append([h.history['acc'], h.history['val_acc']])\n",
        "        print(repeat, end=' ')\n",
        "\n",
        "    histories = np.array(histories)\n",
        "    \n",
        "    # calculate mean and standard deviation across repeats:\n",
        "    mean_acc = histories.mean(axis=0)\n",
        "    std_acc = histories.std(axis=0)\n",
        "    print()\n",
        "    \n",
        "    return mean_acc[0], std_acc[0], mean_acc[1], std_acc[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X01TF08rZ7B_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_acc, std_acc, mean_acc_val, std_acc_val = \\\n",
        "    repeated_training(X_train, y_train, X_test, y_test, do_bn=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3BZUHrkZ80B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_acc_bn, std_acc_bn, mean_acc_val_bn, std_acc_val_bn = \\\n",
        "    repeated_training(X_train, y_train, X_test, y_test, do_bn=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbW8E425Z-Fz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_mean_std(m, s):\n",
        "    plt.plot(m)\n",
        "    plt.fill_between(range(len(m)), m-s, m+s, alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UR-9m0W3Z_7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_mean_std(mean_acc, std_acc)\n",
        "plot_mean_std(mean_acc_val, std_acc_val)\n",
        "plot_mean_std(mean_acc_bn, std_acc_bn)\n",
        "plot_mean_std(mean_acc_val_bn, std_acc_val_bn)\n",
        "plt.ylim(0, 1.01)\n",
        "plt.title(\"Batch Normalization Accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test', 'Train with Batch Normalization', 'Test with Batch Normalization'], loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvrYssCgbBvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conlclusion\n",
        "We have trained 3 models with BN and 3 without. We can see that there is a significant difference between with and without BN. The orange and blue shades are the standard deviations. we can see the the performance is not within the margin of error"
      ]
    },
    {
      "metadata": {
        "id": "kaGLW3SjaBK5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}